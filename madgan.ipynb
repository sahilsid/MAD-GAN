{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "from IPython import display\n",
    "from  tqdm import tqdm\n",
    "from skimage.transform import resize\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyper Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIMENSIONS  = [32,32,3]\n",
    "BUFFER_SIZE       = 60000\n",
    "BATCH_SIZE        = 128\n",
    "NUM_OF_GENERATORS = 5\n",
    "LEARNING_RATE     = 1e-5\n",
    "EPOCHS            = 5000\n",
    "NOISE_DIM         = 256\n",
    "NOISE_MEAN        = 0.0\n",
    "NOISE_STD_DEV     = 0.5\n",
    "WEIGHT_STD_DEV    = 0.02\n",
    "VISUALIZE_COUNT   = 16\n",
    "SEED              = tf.random.normal([VISUALIZE_COUNT,NOISE_DIM],NOISE_MEAN,NOISE_STD_DEV)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set Directory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./{}_G/'.format(NUM_OF_GENERATORS)):\n",
    "            os.makedirs('./{}_G/'.format(NUM_OF_GENERATORS))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Training Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape = (15243, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "dir_data      = \"data/img_align_celeba/\"\n",
    "Ntrain        = 200000 \n",
    "Ntest        = 100 \n",
    "nm_imgs       = np.sort(os.listdir(dir_data))\n",
    "nm_imgs_train = nm_imgs[:Ntrain]\n",
    "nm_imgs_test  = nm_imgs[Ntrain:Ntrain + Ntest]\n",
    "img_shape     = (IMAGE_DIMENSIONS[0],IMAGE_DIMENSIONS[1],IMAGE_DIMENSIONS[2])\n",
    "\n",
    "def get_npdata(nm_imgs_train):\n",
    "    X_train = []\n",
    "    for i, myid in enumerate(nm_imgs_train):\n",
    "        image = load_img(dir_data + \"/\" + myid,\n",
    "                         target_size=img_shape[:2])\n",
    "        image = img_to_array(image)/255.0\n",
    "        X_train.append(image)\n",
    "    X_train = np.array(X_train)\n",
    "    return(X_train)\n",
    "\n",
    "X_train = get_npdata(nm_imgs_train)\n",
    "print(\"X_train.shape = {}\".format(X_train.shape))\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(X_train).shuffle(Ntrain).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generator Model**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generator():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(4*4*512,use_bias = False, input_shape=(NOISE_DIM,), kernel_initializer='random_normal'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(0.2))\n",
    "    \n",
    "    model.add(layers.Reshape((4,4,512)))\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(256,(5,5),strides=(2,2),use_bias=False,padding='same', kernel_initializer=keras.initializers.RandomNormal(stddev=WEIGHT_STD_DEV)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(128,(5,5),strides=(2,2),use_bias=False,padding='same', kernel_initializer=keras.initializers.RandomNormal(stddev=WEIGHT_STD_DEV)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(3,(5,5),strides=(2,2),use_bias=False,padding='same',activation='tanh', kernel_initializer=keras.initializers.RandomNormal(stddev=WEIGHT_STD_DEV)))\n",
    "    model.summary()\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Generator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 8192)              2097152   \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2 (Batc (None, 8192)              32768     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 8, 8, 256)         3276800   \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_1 (Ba (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 16, 16, 128)       819200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_2 (Ba (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 32, 32, 3)         9600      \n",
      "=================================================================\n",
      "Total params: 6,237,056\n",
      "Trainable params: 6,219,904\n",
      "Non-trainable params: 17,152\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff27822bf98>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_generator = Generator() \n",
    "noise  = np.random.normal(0,5,(VISUALIZE_COUNT,NOISE_DIM))\n",
    "generator_output = test_generator(noise,training=False)\n",
    "plt.imshow(np.squeeze(generator_output[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discriminator Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Discriminator():\n",
    "    noise = layers.GaussianNoise(0.05,input_shape=(IMAGE_DIMENSIONS[0],IMAGE_DIMENSIONS[1],IMAGE_DIMENSIONS[2]))\n",
    "    noise.trainable = False\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(noise)\n",
    "    model.add(layers.Conv2D(64,(5,5),strides=(2,2),padding='same',input_shape=(IMAGE_DIMENSIONS[0],IMAGE_DIMENSIONS[1],IMAGE_DIMENSIONS[2]), kernel_initializer=keras.initializers.RandomNormal(stddev=WEIGHT_STD_DEV))) \n",
    "    \n",
    "    model.add(layers.LeakyReLU(0.02))\n",
    "    \n",
    "    model.add(layers.Conv2D(128,(5,5),strides=(2,2),padding='same',input_shape=IMAGE_DIMENSIONS, kernel_initializer=keras.initializers.RandomNormal(stddev=WEIGHT_STD_DEV)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(0.02))\n",
    "\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(NUM_OF_GENERATORS+1, kernel_initializer=keras.initializers.RandomNormal(stddev=WEIGHT_STD_DEV),activation='sigmoid'))\n",
    "    model.summary()\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Discriminator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gaussian_noise (GaussianNois (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 16, 16, 64)        4864      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 8, 8, 128)         204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_3 (Ba (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 49158     \n",
      "=================================================================\n",
      "Total params: 259,462\n",
      "Trainable params: 259,206\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_discriminator = Discriminator() \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define Loss Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy_loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "def generatorLoss(fake_prediction):\n",
    "    dirac_delta = np.zeros(fake_prediction.shape)\n",
    "    dirac_delta[:,NUM_OF_GENERATORS] = 0.999\n",
    "    dirac_delta = tf.convert_to_tensor(dirac_delta)\n",
    "    return cross_entropy_loss(dirac_delta,fake_prediction)\n",
    "\n",
    "\n",
    "def discriminatorLoss(fake_prediction,real_prediction,generator_index):\n",
    "    real_dirac_delta = np.zeros(real_prediction.shape)\n",
    "    real_dirac_delta[:,NUM_OF_GENERATORS] = 0.999\n",
    "    real_dirac_delta = tf.convert_to_tensor(real_dirac_delta)\n",
    "    \n",
    "    fake_dirac_delta = np.zeros(fake_prediction.shape)\n",
    "    fake_dirac_delta[:,generator_index] = 0.999\n",
    "    fake_dirac_delta = tf.convert_to_tensor(fake_dirac_delta)\n",
    "    \n",
    "    total_loss =cross_entropy_loss(fake_dirac_delta,fake_prediction)+ cross_entropy_loss(real_dirac_delta,real_prediction) \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define Optimizers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_optimizer = tf.keras.optimizers.Adam(LEARNING_RATE)\n",
    "\n",
    "generator_optimizer=[None]*NUM_OF_GENERATORS\n",
    "for i in range(0,NUM_OF_GENERATORS):\n",
    "    generator_optimizer[i]=tf.keras.optimizers.Adam(LEARNING_RATE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define Model Instances**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gaussian_noise_1 (GaussianNo (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 64)        4864      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 128)         204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_4 (Ba (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 49158     \n",
      "=================================================================\n",
      "Total params: 259,462\n",
      "Trainable params: 259,206\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 8192)              2097152   \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_5 (Ba (None, 8192)              32768     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 8, 8, 256)         3276800   \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_6 (Ba (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 16, 16, 128)       819200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_7 (Ba (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr (None, 32, 32, 3)         9600      \n",
      "=================================================================\n",
      "Total params: 6,237,056\n",
      "Trainable params: 6,219,904\n",
      "Non-trainable params: 17,152\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 8192)              2097152   \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_8 (Ba (None, 8192)              32768     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTr (None, 8, 8, 256)         3276800   \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_9 (Ba (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTr (None, 16, 16, 128)       819200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_10 (B (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTr (None, 32, 32, 3)         9600      \n",
      "=================================================================\n",
      "Total params: 6,237,056\n",
      "Trainable params: 6,219,904\n",
      "Non-trainable params: 17,152\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 8192)              2097152   \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_11 (B (None, 8192)              32768     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_9 (Conv2DTr (None, 8, 8, 256)         3276800   \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_12 (B (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_10 (Conv2DT (None, 16, 16, 128)       819200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_13 (B (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_11 (Conv2DT (None, 32, 32, 3)         9600      \n",
      "=================================================================\n",
      "Total params: 6,237,056\n",
      "Trainable params: 6,219,904\n",
      "Non-trainable params: 17,152\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 8192)              2097152   \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_14 (B (None, 8192)              32768     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)   (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "reshape_4 (Reshape)          (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_12 (Conv2DT (None, 8, 8, 256)         3276800   \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_15 (B (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_13 (Conv2DT (None, 16, 16, 128)       819200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_16 (B (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_14 (Conv2DT (None, 32, 32, 3)         9600      \n",
      "=================================================================\n",
      "Total params: 6,237,056\n",
      "Trainable params: 6,219,904\n",
      "Non-trainable params: 17,152\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 8192)              2097152   \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_17 (B (None, 8192)              32768     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)   (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "reshape_5 (Reshape)          (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_15 (Conv2DT (None, 8, 8, 256)         3276800   \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_18 (B (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_16 (Conv2DT (None, 16, 16, 128)       819200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_19 (B (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_17 (Conv2DT (None, 32, 32, 3)         9600      \n",
      "=================================================================\n",
      "Total params: 6,237,056\n",
      "Trainable params: 6,219,904\n",
      "Non-trainable params: 17,152\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = Discriminator()\n",
    "\n",
    "generator=[None]*NUM_OF_GENERATORS\n",
    "for i in range(0,NUM_OF_GENERATORS):\n",
    "    generator[i]=Generator()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define Checkpoints**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_noise():\n",
    "    return tf.random.normal((BATCH_SIZE,NOISE_DIM),NOISE_MEAN,NOISE_STD_DEV)\n",
    "\n",
    "def training_step(real_image):\n",
    "    input_noise = generate_noise()\n",
    "    for i in range(0,NUM_OF_GENERATORS):\n",
    "        with tf.GradientTape() as generator_tape, tf.GradientTape() as discriminator_tape :\n",
    "            fake_image  = generator[i](input_noise,training=True)\n",
    "\n",
    "            real_output = discriminator(real_image,training=True)\n",
    "            fake_output = discriminator(fake_image,training=True)\n",
    "            \n",
    "            generator_loss     = generatorLoss(fake_output)\n",
    "            discriminator_loss = discriminatorLoss(fake_output,real_output,i)\n",
    "\n",
    "        generator_gradient     = generator_tape.gradient(generator_loss,generator[i].trainable_variables) \n",
    "        discriminator_gradient = discriminator_tape.gradient(discriminator_loss,discriminator.trainable_variables) \n",
    "        \n",
    "        generator_optimizer[i].apply_gradients(zip(generator_gradient,generator[i].trainable_variables))\n",
    "        discriminator_optimizer.apply_gradients(zip(discriminator_gradient,discriminator.trainable_variables))\n",
    "\n",
    "def train_model(no_of_epochs,data):\n",
    "    for epoch in range(0,no_of_epochs):\n",
    "        \n",
    "        dataset = tqdm(data)\n",
    "        for image_batch in dataset :\n",
    "            dataset.set_description(' Epoch %s '%(epoch+1))\n",
    "            training_step(image_batch)\n",
    "        \n",
    "        generate_visualization(epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_concatenated(image_path_list,filename):\n",
    "    imgs    = [ PIL.Image.open(i) for i in image_path_list ]\n",
    "    min_shape = sorted( [(np.sum(i.size), i.size ) for i in imgs])[0][1]\n",
    "    imgs_comb = np.hstack( (np.asarray( i.resize(min_shape) ) for i in imgs ) )\n",
    "    imgs_comb = PIL.Image.fromarray( imgs_comb)\n",
    "    imgs_comb.save('./{}_G/Result/{}.png'.format(NUM_OF_GENERATORS,filename))\n",
    "    \n",
    "def generate_visualization(epoch):\n",
    "    imgs = []\n",
    "    for i in range(0,NUM_OF_GENERATORS):\n",
    "        display.clear_output(wait=True)\n",
    "        fig = plt.figure(figsize=(4,4))\n",
    "        generator_output = generator[i](SEED,training = False)\n",
    "        for j in range(generator_output.shape[0]):\n",
    "            plt.subplot(4, 4, j+1)\n",
    "            plt.imshow(generator_output[j, :, :, :] )\n",
    "            plt.axis('off')\n",
    "            \n",
    "        if not os.path.exists('./{}_G/{}/'.format(NUM_OF_GENERATORS,i+1)):\n",
    "            os.makedirs('./{}_G/{}/'.format(NUM_OF_GENERATORS,i+1))\n",
    "            \n",
    "        plt.savefig('./{}_G/{}/{:04d}.png'.format(NUM_OF_GENERATORS,i+1,epoch))\n",
    "        imgs.append('./{}_G/{}/{:04d}.png'.format(NUM_OF_GENERATORS,i+1,epoch))\n",
    "    \n",
    "      \n",
    "    if not os.path.exists('./{}_G/Result/'.format(NUM_OF_GENERATORS)):\n",
    "        os.makedirs('./{}_G/Result/'.format(NUM_OF_GENERATORS))\n",
    "    \n",
    "    generate_concatenated(imgs,epoch+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      " Epoch 98 : : 97it [00:58,  1.64it/s]"
     ]
    }
   ],
   "source": [
    "train_model(EPOCHS,train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_visualization(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(EPOCHS,train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
